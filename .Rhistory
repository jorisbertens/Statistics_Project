df_try[] <- lapply(df_try, gsub, pattern =",", replacement = ".", fixed = TRUE)
df_try[] <- lapply(df_try, gsub, pattern ="$", replacement = "", fixed = TRUE)
df_try$Business.regulations <- gsub("[-].*","", df_try$Business.regulations)
df_try$Fiscal.Freedom <- as.numeric(df_try$Fiscal.Freedom)
df_try$Business.Freedom <- as.numeric(df_try$Business.Freedom)
df_try$Labor.Freedom <- as.numeric(df_try$Labor.Freedom)
df_try$Monetary.Freedom <- as.numeric(df_try$Monetary.Freedom)
df_try$Trade.Freedom <- as.numeric(df_try$Trade.Freedom)
df_try$Investment.Freedom <- as.numeric(df_try$Investment.Freedom)
df_try$Financial.Freedom <- as.numeric(df_try$Financial.Freedom)
df_try$Population..Millions. <- as.numeric(df_try$Population..Millions.)
df_try$GDP..Billions..PPP. <- as.numeric(df_try$GDP..Billions..PPP.)
df_try$FDI.Inflow..Millions. <- as.numeric(df_try$FDI.Inflow..Millions.)
df_try$Conflicts <- as.numeric(df_try$Conflicts)
df_try$Security...Safety <- as.numeric(df_try$Security...Safety)
df_try$Domestic.Movement <- as.numeric(df_try$Domestic.Movement)
df_try$Foreign.Movement <- as.numeric(df_try$Foreign.Movement)
df_try$Religion <- as.numeric(df_try$Religion)
df_try$Establishing.and.Operating.Political.Parties <- as.numeric(df_try$Establishing.and.Operating.Political.Parties)
df_try$Operating.Educational <- as.numeric(df_try$Operating.Educational)
df_try$Political.Pressures.and.Controls.on.Media.Content <- as.numeric(df_try$Political.Pressures.and.Controls.on.Media.Content)
df_try$Parental.Authority..In.Marriage <- as.numeric(df_try$Parental.Authority..In.Marriage)
df_try$Transfers.and.subsidies <- as.numeric(df_try$Transfers.and.subsidies)
df_try$Government.enterprises.and.investment <- as.numeric(df_try$Government.enterprises.and.investment)
df_try$Protection.of.property.rights <- as.numeric(df_try$Protection.of.property.rights)
df_try$Money.growth <- as.numeric(df_try$Money.growth)
df_try$Labor.market.regulations <- as.numeric(df_try$Labor.market.regulations)
df_try$Hiring.and.firing.regulations <- as.numeric(df_try$Hiring.and.firing.regulations)
df_try$Starting.a..business <- as.numeric(df_try$Starting.a..business)
df_try$Business.regulations <- as.numeric(df_try$Business.regulations)
df_try$Laws.and.Regulations.that.Influence.Media.Content <- as.numeric(df_try$Laws.and.Regulations.that.Influence.Media.Content)
df_try$Women.s.Security...Safety <- as.numeric(df_try$Women.s.Security...Safety)
df_try$Criminal.Justice <- as.numeric(df_try$Criminal.Justice)
df_try$Unemployment.... <- as.numeric(df_try$Unemployment....)
sapply(df_try, class)
# change - to NA
df_try[df_try == "-"] <- NA
# Missing values
sum(is.na(df_try))
# Missing values per column
map(df_try, ~sum(is.na(.)))
# Method 1 of NA imputation = predicted value from LR to impute
imp <- mice(df_try, method = "norm.predict", m = 1)
data_imp1 <- complete(imp)
# Method 2 of NA imputation = imputing by the mean
ok <- sapply(df_try, is.numeric)
data_imp2 = df_try
data_imp2[ok] <- lapply(data_imp2[ok], na.aggregate)
# Method 3 of NA imputation = by median?
ok <- sapply(df_try, is.numeric)
data_imp3 = df_try
data_imp3[ok] <- lapply(data_imp3[ok], na.)
cor_tds <- cor(data_imp1[-1], data_imp1[-1], method = "pearson")
cor_df <- data.frame(cor=cor_tds[1:30,31], varn = names(cor_tds[1:30,31]))
cor_df <- cor_df%>%mutate(cor_abs = abs(cor)) %>% arrange(desc(cor_abs))
plot(cor_df$cor_abs)
list_varn <- cor_df %>% filter(cor_abs>0.1)
filter_df <- data.frame(data_imp1) %>% select(Unemployment...., one_of(as.character(list_varn$varn)))
View(filter_df)
View(filter_df)
colnames(filter_df)
control <- trainControl(method="repeatedcv", number=10, repeats=3)
# train the model
model <- train(Unemployment....~., data=data_imp1[-1], method="lm", preProcess="scale", trControl=control)
# estimate variable importance
importance <- varImp(model, scale=FALSE)
# summarize importance
print(importance)
# plot importance
plot(importance)
fit_glm = glm(Unemployment....~., data = data_imp1[-1])
varImp(fit_glm)
# summarize importance
print(importance)
# plot importance
plot(importance)
imp <- mice(df_try, method = "norm.predict", m = 1)
data_imp1 <- complete(imp)
control <- trainControl(method="repeatedcv", number=10, repeats=3)
# train the model
model <- train(Unemployment....~., data=data_imp1[-1], method="lm", preProcess="scale", trControl=control)
# estimate variable importance
importance <- varImp(model, scale=FALSE)
# summarize importance
print(importance)
# plot importance
plot(importance)
control <- trainControl(method="repeatedcv", number=10, repeats=3)
# train the model
model <- train(Unemployment....~., data=data_imp1[-1], method="lm", preProcess="scale", trControl=control)
# estimate variable importance
importance <- varImp(model, scale=FALSE)
# summarize importance
print(importance)
# plot importance
plot(importance)
control <- trainControl(method="repeatedcv", number=10, repeats=3)
# train the model
model <- train(Unemployment....~., data=data_imp1[-1], method="lm", preProcess="scale", trControl=control)
# estimate variable importance
importance <- varImp(model, scale=FALSE)
# summarize importance
print(importance)
# plot importance
plot(importance)
imp <- mice(df_try, method = "norm.predict", m = 1)
data_imp1 <- complete(imp)
control <- trainControl(method="repeatedcv", number=10, repeats=3)
# train the model
model <- train(Unemployment....~., data=data_imp1[-1], method="lm", preProcess="scale", trControl=control)
# estimate variable importance
importance <- varImp(model, scale=FALSE)
# summarize importance
print(importance)
# plot importance
plot(importance)
rm(list=ls())
library(tidyr)
library(naniar)
library(dplyr)
library(tidyverse)
library(Hmisc)
library(mice)
library(tidyverse)
library(zoo)
library(FactoMineR)
library(factoextra)
library(corrgram)
library(mlbench)
library(FSelector)
library(caret)
# Load the Data
get_data<-function(data, sep=","){
df <- read.csv(data, header = TRUE, sep)
}
df1 = get_data("Data/EconomicFreedomIndex.csv", sep=";")
df2 = get_data("Data/HumanFreedomIndex.csv")
df2 = df2[(df2$Year=="2016"),]
# Join the Data
join_data<-function(df1,df2){
df_new <- merge(df1,df2,by.x = c("Country.Name"),by.y = c("Countries"))
return(df_new)
}
df_join = join_data(df1,df2)
# delete first columns
df_join= df_join[-2]
df_join= df_join[-2]
df_join= df_join[-2]
df_join= df_join[-2]
df_join= df_join[-2]
df_join= df_join[-2]
df_join= df_join[-2]
# delete columns that include "Chang"
df_try = df_join[, -grep("Chang", colnames(df_join))]
# manually selected columns
cols = c(1, 4 ,6:11, 18, 19, 25, 48, 56, 57, 58, 66, 71, 77, 89, 95, 107, 109, 119, 128, 162, 157, 165, 169, 88, 55, 35, 23)
df_try = df_try[,cols]
# get information about the data
di <- describe(df_try)
di
sapply(df_try, typeof)
sapply(df_try, class)
df_try <- data.frame(lapply(df_try, as.character), stringsAsFactors=FALSE)
df_try[] <- lapply(df_try, gsub, pattern =".", replacement = "", fixed = TRUE)
df_try[] <- lapply(df_try, gsub, pattern =",", replacement = ".", fixed = TRUE)
df_try[] <- lapply(df_try, gsub, pattern ="$", replacement = "", fixed = TRUE)
df_try$Business.regulations <- gsub("[-].*","", df_try$Business.regulations)
df_try$Fiscal.Freedom <- as.numeric(df_try$Fiscal.Freedom)
df_try$Business.Freedom <- as.numeric(df_try$Business.Freedom)
df_try$Labor.Freedom <- as.numeric(df_try$Labor.Freedom)
df_try$Monetary.Freedom <- as.numeric(df_try$Monetary.Freedom)
df_try$Trade.Freedom <- as.numeric(df_try$Trade.Freedom)
df_try$Investment.Freedom <- as.numeric(df_try$Investment.Freedom)
df_try$Financial.Freedom <- as.numeric(df_try$Financial.Freedom)
df_try$Population..Millions. <- as.numeric(df_try$Population..Millions.)
df_try$GDP..Billions..PPP. <- as.numeric(df_try$GDP..Billions..PPP.)
df_try$FDI.Inflow..Millions. <- as.numeric(df_try$FDI.Inflow..Millions.)
df_try$Conflicts <- as.numeric(df_try$Conflicts)
df_try$Security...Safety <- as.numeric(df_try$Security...Safety)
df_try$Domestic.Movement <- as.numeric(df_try$Domestic.Movement)
df_try$Foreign.Movement <- as.numeric(df_try$Foreign.Movement)
df_try$Religion <- as.numeric(df_try$Religion)
df_try$Establishing.and.Operating.Political.Parties <- as.numeric(df_try$Establishing.and.Operating.Political.Parties)
df_try$Operating.Educational <- as.numeric(df_try$Operating.Educational)
df_try$Political.Pressures.and.Controls.on.Media.Content <- as.numeric(df_try$Political.Pressures.and.Controls.on.Media.Content)
df_try$Parental.Authority..In.Marriage <- as.numeric(df_try$Parental.Authority..In.Marriage)
df_try$Transfers.and.subsidies <- as.numeric(df_try$Transfers.and.subsidies)
df_try$Government.enterprises.and.investment <- as.numeric(df_try$Government.enterprises.and.investment)
df_try$Protection.of.property.rights <- as.numeric(df_try$Protection.of.property.rights)
df_try$Money.growth <- as.numeric(df_try$Money.growth)
df_try$Labor.market.regulations <- as.numeric(df_try$Labor.market.regulations)
df_try$Hiring.and.firing.regulations <- as.numeric(df_try$Hiring.and.firing.regulations)
df_try$Starting.a..business <- as.numeric(df_try$Starting.a..business)
df_try$Business.regulations <- as.numeric(df_try$Business.regulations)
df_try$Laws.and.Regulations.that.Influence.Media.Content <- as.numeric(df_try$Laws.and.Regulations.that.Influence.Media.Content)
df_try$Women.s.Security...Safety <- as.numeric(df_try$Women.s.Security...Safety)
df_try$Criminal.Justice <- as.numeric(df_try$Criminal.Justice)
df_try$Unemployment.... <- as.numeric(df_try$Unemployment....)
sapply(df_try, class)
# change - to NA
df_try[df_try == "-"] <- NA
# Missing values
sum(is.na(df_try))
# Missing values per column
map(df_try, ~sum(is.na(.)))
# Method 1 of NA imputation = predicted value from LR to impute
imp <- mice(df_try, method = "norm.predict", m = 1)
data_imp1 <- complete(imp)
control <- trainControl(method="repeatedcv", number=10, repeats=3)
# train the model
model <- train(Unemployment....~., data=data_imp1[-1], method="lm", preProcess="scale", trControl=control)
# estimate variable importance
importance <- varImp(model, scale=FALSE)
# summarize importance
print(importance)
# plot importance
plot(importance)
rm(list=ls())
library(tidyr)
library(naniar)
library(dplyr)
library(tidyverse)
library(Hmisc)
library(mice)
library(tidyverse)
library(zoo)
library(FactoMineR)
library(factoextra)
library(corrgram)
library(mlbench)
library(FSelector)
library(caret)
# Load the Data
get_data<-function(data, sep=","){
df <- read.csv(data, header = TRUE, sep)
}
df1 = get_data("Data/EconomicFreedomIndex.csv", sep=";")
df2 = get_data("Data/HumanFreedomIndex.csv")
df2 = df2[(df2$Year=="2016"),]
# Join the Data
join_data<-function(df1,df2){
df_new <- merge(df1,df2,by.x = c("Country.Name"),by.y = c("Countries"))
return(df_new)
}
df_join = join_data(df1,df2)
# delete first columns
df_join= df_join[-2]
df_join= df_join[-2]
df_join= df_join[-2]
df_join= df_join[-2]
df_join= df_join[-2]
df_join= df_join[-2]
df_join= df_join[-2]
# delete columns that include "Chang"
df_try = df_join[, -grep("Chang", colnames(df_join))]
# manually selected columns
cols = c(1, 4 ,6:11, 18, 19, 25, 48, 56, 57, 58, 66, 71, 77, 89, 95, 107, 109, 119, 128, 162, 157, 165, 169, 88, 55, 35, 23)
df_try = df_try[,cols]
# get information about the data
di <- describe(df_try)
di
sapply(df_try, typeof)
sapply(df_try, class)
df_try <- data.frame(lapply(df_try, as.character), stringsAsFactors=FALSE)
df_try[] <- lapply(df_try, gsub, pattern =".", replacement = "", fixed = TRUE)
df_try[] <- lapply(df_try, gsub, pattern =",", replacement = ".", fixed = TRUE)
df_try[] <- lapply(df_try, gsub, pattern ="$", replacement = "", fixed = TRUE)
df_try$Business.regulations <- gsub("[-].*","", df_try$Business.regulations)
df_try$Fiscal.Freedom <- as.numeric(df_try$Fiscal.Freedom)
df_try$Business.Freedom <- as.numeric(df_try$Business.Freedom)
df_try$Labor.Freedom <- as.numeric(df_try$Labor.Freedom)
df_try$Monetary.Freedom <- as.numeric(df_try$Monetary.Freedom)
df_try$Trade.Freedom <- as.numeric(df_try$Trade.Freedom)
df_try$Investment.Freedom <- as.numeric(df_try$Investment.Freedom)
df_try$Financial.Freedom <- as.numeric(df_try$Financial.Freedom)
df_try$Population..Millions. <- as.numeric(df_try$Population..Millions.)
df_try$GDP..Billions..PPP. <- as.numeric(df_try$GDP..Billions..PPP.)
df_try$FDI.Inflow..Millions. <- as.numeric(df_try$FDI.Inflow..Millions.)
df_try$Conflicts <- as.numeric(df_try$Conflicts)
df_try$Security...Safety <- as.numeric(df_try$Security...Safety)
df_try$Domestic.Movement <- as.numeric(df_try$Domestic.Movement)
df_try$Foreign.Movement <- as.numeric(df_try$Foreign.Movement)
df_try$Religion <- as.numeric(df_try$Religion)
df_try$Establishing.and.Operating.Political.Parties <- as.numeric(df_try$Establishing.and.Operating.Political.Parties)
df_try$Operating.Educational <- as.numeric(df_try$Operating.Educational)
df_try$Political.Pressures.and.Controls.on.Media.Content <- as.numeric(df_try$Political.Pressures.and.Controls.on.Media.Content)
df_try$Parental.Authority..In.Marriage <- as.numeric(df_try$Parental.Authority..In.Marriage)
df_try$Transfers.and.subsidies <- as.numeric(df_try$Transfers.and.subsidies)
df_try$Government.enterprises.and.investment <- as.numeric(df_try$Government.enterprises.and.investment)
df_try$Protection.of.property.rights <- as.numeric(df_try$Protection.of.property.rights)
df_try$Money.growth <- as.numeric(df_try$Money.growth)
df_try$Labor.market.regulations <- as.numeric(df_try$Labor.market.regulations)
df_try$Hiring.and.firing.regulations <- as.numeric(df_try$Hiring.and.firing.regulations)
df_try$Starting.a..business <- as.numeric(df_try$Starting.a..business)
df_try$Business.regulations <- as.numeric(df_try$Business.regulations)
df_try$Laws.and.Regulations.that.Influence.Media.Content <- as.numeric(df_try$Laws.and.Regulations.that.Influence.Media.Content)
df_try$Women.s.Security...Safety <- as.numeric(df_try$Women.s.Security...Safety)
df_try$Criminal.Justice <- as.numeric(df_try$Criminal.Justice)
df_try$Unemployment.... <- as.numeric(df_try$Unemployment....)
sapply(df_try, class)
# change - to NA
df_try[df_try == "-"] <- NA
# Missing values
sum(is.na(df_try))
# Missing values per column
map(df_try, ~sum(is.na(.)))
# Method 1 of NA imputation = predicted value from LR to impute
imp <- mice(df_try, method = "norm.predict", m = 1)
data_imp1 <- complete(imp)
write.csv(data_imp1, file = "Data/clean_dataset.csv")
cor_tds <- cor(data_imp1[-1], data_imp1[-1], method = "pearson")
cor_df <- data.frame(cor=cor_tds[1:30,31], varn = names(cor_tds[1:30,31]))
cor_df <- cor_df%>%mutate(cor_abs = abs(cor)) %>% arrange(desc(cor_abs))
plot(cor_df$cor_abs)
View(data_imp1)
View(cor_df)
View(df_join)
View(data_imp1)
View(cor_df)
cor_df <- data.frame(cor=cor_tds[1:31,31], varn = names(cor_tds[1:31,31]))
View(cor_df)
cor_df <- data.frame(cor=cor_tds[1:30,31], varn = names(cor_tds[1:30,31]))
cor_df <- cor_df%>%mutate(cor_abs = abs(cor)) %>% arrange(desc(cor_abs))
plot(cor_df$cor_abs)
cor_tds <- cor(data_imp1[-1], data_imp1[-1], method = "pearson")
cor_df <- data.frame(cor=cor_tds[1:30,31], varn = names(cor_tds[1:30,31]))
cor_df <- cor_df%>%mutate(cor_abs = abs(cor)) %>% arrange(desc(cor_abs))
plot(cor_df$cor_abs)
list_varn <- cor_df %>% filter(cor_abs>0.1)
filter_df <- data.frame(data_imp1) %>% select(Unemployment...., one_of(as.character(list_varn$varn)))
head(filter_df)
corrgram(filter_df,lower.panel=panel.cor,upper.panel=panel.pie, cor.method = "pearson")
# either go with feature importance done by Alex or using the Correlation
#df_pca = important_features[-1]
df_pca = filter_df[-1]
sapply(df_pca, class)
prcomp(df_pca, scale.unit = TRUE, ncp = 5, graph = TRUE)
res.pca = prcomp(df_pca, scale. = TRUE , graph = FALSE)
plot(res.pca, type="l")
print(res.pca)
eig.val = get_eigenvalue(res.pca)
eig.val
fviz_screeplot(res.pca, addlabels = TRUE, ylim = c(0, 50))
head(var$coord)
head(var$cos2)
head(var$contrib)
print(res.pca)
eig.val = get_eigenvalue(res.pca)
eig.val
fviz_screeplot(res.pca, addlabels = TRUE, ylim = c(0, 50))
var = get_pca_var(res.pca)
head(var$coord)
head(var$cos2)
head(var$contrib)
head(var$coord, 4)
fviz_pca_var(res.pca, col.var = "black")
library("corrplot")
corrplot(var$cos2, is.corr=FALSE)
corrplot(var$cos2, is.corr=TRUE)
corrplot(var$cos2, is.corr=FALSE)
fviz_cos2(res.pca, choice = "var", axes = 1)
fviz_cos2(res.pca, choice = "var", axes = 1)
corrplot(var$cos2, is.corr=FALSE)
fviz_cos2(res.pca, choice = "var", axes = 1)
# Color by cos2 values: quality on the factor map
fviz_pca_var(res.pca, col.var = "cos2",
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
repel = TRUE # Avoid text overlapping
)
# Change the transparency by cos2 values
fviz_pca_var(res.pca, alpha.var = "cos2")
head(var$contrib, 4)
library("corrplot")
corrplot(var$contrib, is.corr=FALSE)
corrplot(var$contrib, is.corr=FALSE)
# Contributions of variables to PC1
fviz_contrib(res.pca, choice = "var", axes = 1, top = 10)
# Contributions of variables to PC2
fviz_contrib(res.pca, choice = "var", axes = 2, top = 10)
# Contributions of variables to PC3
fviz_contrib(res.pca, choice = "var", axes = 3, top = 10)
# Contributions of variables to PC4
fviz_contrib(res.pca, choice = "var", axes = 4, top = 10)
# Contributions of variables to PC5
fviz_contrib(res.pca, choice = "var", axes = 5, top = 10)
fviz_pca_ind(res.pca)
fviz_pca_ind(res.pca, col.ind = "cos2",
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
repel = TRUE # Avoid text overlapping (slow if many points)
)
fviz_pca_ind(res.pca, pointsize = "cos2",
pointshape = 21, fill = "#E7B800",
repel = TRUE # Avoid text overlapping (slow if many points)
)
fviz_pca_ind(res.pca, col.ind = "cos2",
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
repel = TRUE # Avoid text overlapping (slow if many points)
)
fviz_pca_ind(res.pca, pointsize = "cos2",
pointshape = 21, fill = "#E7B800",
repel = TRUE # Avoid text overlapping (slow if many points)
)
summary(res.pca)
spca = summary(res.pca)
plot(spca$importance[3,], type="l")
pca_df <- data.frame(res.pca$x)
pca_df <- pca_df %>% select(PC1,PC2,PC3,PC4,PC5)
pca_df$Unemployment = filter_df$Unemployment....
pca_df$County = data_imp1$Country.Name
write.csv(pca_df, file = "Data/pca_dataset.csv")
split(pca_df, cut(pca_df$anim, 4))
split(pca_df, cut(pca_df$Unemployment, 4))
df_r = write.csv(pca_df, file = "Data/pca_dataset.csv")
df_r =  split(pca_df, cut(pca_df$Unemployment, 4))
View(df_r)
plit(pca_df, cut(pca_df$Unemployment, 4))
split(pca_df, cut(pca_df$Unemployment, 4))
View(df_pca)
View(pca_df)
library(Hmisc)
split(pca_df, cut(pca_df$Unemployment, g=4))
split(pca_df, cut2(pca_df$Unemployment, g=4))
View(pca_df)
pca_df$bin_unempl = cut(pca_df$Unemployment, 3)
View(pca_df)
pca_df$bin_unempl = cut(pca_df$Unemployment, 4)
View(pca_df)
pca_df$bin_unempl = cut(pca_df$Unemployment, 6)
View(pca_df)
fviz_pca_ind(res.pca, col.ind = pca_df$bin_unempl ,
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
repel = TRUE # Avoid text overlapping (slow if many points)
)
fviz_pca_ind(res.pca, col.ind = pca_df$Unemployment ,
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
repel = TRUE # Avoid text overlapping (slow if many points)
)
"cos2"
fviz_pca_ind(res.pca, col.ind = "cos2",
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
repel = TRUE # Avoid text overlapping (slow if many points)
)
get_full_data<-function(data, sep=","){
df <- read.csv(data, header = TRUE, sep)
}
df = get_full_data("Data/pca_dataset.csv")
df2 = df %>% select(-1,-2,-33)
df2 = df %>% select(-1,-7,-8)
d<-dist(df2)
# Elbow method
fviz_nbclust(df2, hcut, method = "wss") +
geom_vline(xintercept = 4, linetype = 2)+
labs(subtitle = "Elbow method")
fviz_nbclust(df2, hcut, method = "silhouette")+
labs(subtitle = "Silhouette method")
## Impute by mean
for(i in 1:ncol(df2)){
df2[is.na(df2[,i]), i] <- mean(df2[,i], na.rm = TRUE)
}
# Gap statistic
# nboot = 50 to keep the function speedy.
# recommended value: nboot= 500 for your analysis.
# Use verbose = FALSE to hide computing progression.
set.seed(123)
fviz_nbclust(df2, hcut, nstart = 25,  method = "gap_stat", nboot = 50)+
labs(subtitle = "Gap statistic method")
library("NbClust")
nb <- NbClust(df2, distance = "euclidean", min.nc = 2,
max.nc = 10, method = "kmeans")
fviz_nbclust(nb)
View(df)
df2 = df %>% select(-1,-7,-8)
View(df2)
# Elbow method
fviz_nbclust(df2, hcut, method = "wss") +
geom_vline(xintercept = 4, linetype = 2)+
labs(subtitle = "Elbow method")
fviz_nbclust(df2, hcut, method = "silhouette")+
labs(subtitle = "Silhouette method")
## Impute by mean
for(i in 1:ncol(df2)){
df2[is.na(df2[,i]), i] <- mean(df2[,i], na.rm = TRUE)
}
# Gap statistic
# nboot = 50 to keep the function speedy.
# recommended value: nboot= 500 for your analysis.
# Use verbose = FALSE to hide computing progression.
set.seed(123)
fviz_nbclust(df2, hcut, nstart = 25,  method = "gap_stat", nboot = 50)+
labs(subtitle = "Gap statistic method")
library("NbClust")
nb <- NbClust(df2, distance = "euclidean", min.nc = 2,
max.nc = 10, method = "kmeans")
fviz_nbclust(nb)
fit_ward<-hclust(d,method="ward.D")
plot(fit_ward)
rect.hclust(fit_ward, k=3, border="red")
groups_ward <- cutree(fit_ward, k=3)
df$groups_ward<-groups_ward
table(df$groups_ward,df$groups_ward)
plot(fit_ward, labels=df$County)
rect.hclust(fit_ward, k=3, border="red")
plot(fit_ward, labels=df$County)
rect.hclust(fit_ward, k=3, border="red")
plot(1:10)
plot(1:20)
plot(4:20)
dev.new(width=5, height=4)
plot(fit_ward, labels=df$County)
dev.new(width=5, height=4)
plot(fit_ward, labels=df$County)
dev.new(width=5, height=4)
